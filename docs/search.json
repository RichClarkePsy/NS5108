[{"path":"index.html","id":"welcome-to-the-ns5108-regression-handbook","chapter":"1 Welcome to the NS5108 Regression Handbook","heading":"1 Welcome to the NS5108 Regression Handbook","text":"learning regression analysis first time just want refresher, handbook help navigate complexity.Throughout book likely encounter complicated new words concepts, worry. assist , included glossary one last pages guide. , , concept still clear, ’ve included list recommended sources (even nice, easy understand, YouTube videos) explain things different angle.guide designed work alongside NS5108 lectures, replace . Attending lectures give chance ask questions get better grasp material, making learning process easier.Now, get started. Yes, going maths, yes going formulas, sorry can’t teach statistics without aspects. However, different depths can learn statistics. handbook give basics, also allows delve little deeper theory behind regression modelling work. understand absolutely everything first read , ok fact completely understandable!exercises data mention throughout book can found NS5108 Moodle page. enrolled module want try exercises , can email rclarke8@glos.ac.uk, send data.feeling anxious diving statistics, know alone; many people feel way.Think learning statistics like learning drive ride bike. Initially, full painful stops bumps, persistence, things eventually start make sense. Even struggled greatly first encountered material, realised incredibly useful powerful can , motivation skyrocketed, got hump now ’m hooked life. Just remember learning marathon, perfectly fine move pace. goal make journey smooth possible clear explanations practical exercises.find stuck, hesitate ask help. graduate teaching assistants willing explain concepts repeatedly various ways; fact, welcome —keeps us toes. Asking questions integral part learning process, support every step way. , take deep breath, patient kind . skills acquire serve well academic journey hopefully lead meaningful impact future work.","code":""},{"path":"index.html","id":"where-is-the-handbook-for-anova","chapter":"1 Welcome to the NS5108 Regression Handbook","heading":"1.1 Where is the handbook for ANOVA?","text":"regression guide little summer project, details related ANOVA already excellent guide written Dr Kim Schenke Moodle area: Psychology Statistics Workbook JASP. page contains wide range content related research methods, JASP, difference testing.","code":""},{"path":"introduction-to-regression-analysis.html","id":"introduction-to-regression-analysis","chapter":"2 Introduction to Regression analysis","heading":"2 Introduction to Regression analysis","text":"Regression analysis powerful statistical tool investigates relationships variables. core, technique used understand quantify one variable (criterion variable) changes response another several others (predictor variables). merely determining singular correlation, regression analysis offers nuance, enabling researchers predict outcomes uncover sophisticated patterns embedded within datasets.","code":""},{"path":"introduction-to-regression-analysis.html","id":"data-driven-decision-making","chapter":"2 Introduction to Regression analysis","heading":"2.1 Data-driven decision making","text":"2011 film Moneyball based true story Oakland Athletics baseball team's 2002 season. general manager, Billy Beane (played Brad Pitt film), faced problem: limited budget put together winning team. Rather relying traditional baseball scouting methods, often depended heavily scouts' intuitions prone various biases, Beane employed skills young Yale economics graduate named Peter Brand (played Jonah Hill). Brand used statistical analysis evaluate players' values.traditional method valuing players subjective. Scouts often looked physique players, style, moved, even things like attractiveness girlfriends indicator confidence. Beane Brand shifted focus objective evidence, including statistics.core, analytics used \"Moneyball\" predicting runs, importantly, wins. Using regression analysis, determine statistics strongly correlated creating runs. understanding leads runs, use build model aid player acquisition decisions.film (also far nerdy book Michael Lewis) highlights tensions arise data-driven metrics clash entrenched traditional norms. Yet, time progresses, efficacy analytical techniques becomes increasingly evident. Today, rarity encounter professional sports team incorporate form statistical analysis strategy decision-making processes, showcasing undeniable impact relevance regression modern world.","code":""},{"path":"introduction-to-regression-analysis.html","id":"further-real-world-examples","chapter":"2 Introduction to Regression analysis","heading":"2.2 Further real world examples","text":"course, ’s just world sports taken advantage regression analysis inform decision making. examples everyday life regression analysis plays role.Streaming Services Recommendations: probably use platforms like Netflix, Spotify, YouTube. platforms utilise regression analysis predict shows, songs, videos might like based past behaviour behaviour others similar tastes.Streaming Services Recommendations: probably use platforms like Netflix, Spotify, YouTube. platforms utilise regression analysis predict shows, songs, videos might like based past behaviour behaviour others similar tastes.Predicting Box-office Income Different Forms Advertising: Film producers often use regression analyses gauge adverts, TV spots social media campaigns, influence cinema ticket sales, optimising advertising budgets upcoming films based insights.Predicting Box-office Income Different Forms Advertising: Film producers often use regression analyses gauge adverts, TV spots social media campaigns, influence cinema ticket sales, optimising advertising budgets upcoming films based insights.","code":""},{"path":"introduction-to-regression-analysis.html","id":"use-of-regression-analysis-in-psychology","chapter":"2 Introduction to Regression analysis","heading":"2.3 Use of regression analysis in psychology","text":"Regression analysis also cornerstone psychological research, allows psychologists simultaneously explore dissect influence numerous variables single outcome variable. comprehensive approach indispensable field like psychology, behaviours mental processes often outcome web interconnected variables.instance:Predictors Job Satisfaction: Organizational psychologists use regression determine factors (e.g., salary, working hours, team dynamics, leadership style) significant predictors job satisfaction among employees.Predictors Job Satisfaction: Organizational psychologists use regression determine factors (e.g., salary, working hours, team dynamics, leadership style) significant predictors job satisfaction among employees.Influence Social Behaviours: Social psychologists might employ regression analysis understand various factors like media exposure, peer influence, past experiences predict certain social behaviours attitudes, aggression altruism.Influence Social Behaviours: Social psychologists might employ regression analysis understand various factors like media exposure, peer influence, past experiences predict certain social behaviours attitudes, aggression altruism.Personally interested public health climate change. Regression indispensable studying areas like :Determinants Vaccine Hesitancy: used regression analysis predict likelihood individuals hesitant take vaccines. Predictors analysis demographic factors like age education level, psychological factors risk perception trust healthcare, well societal variables like exposure misinformation social media.Determinants Vaccine Hesitancy: used regression analysis predict likelihood individuals hesitant take vaccines. Predictors analysis demographic factors like age education level, psychological factors risk perception trust healthcare, well societal variables like exposure misinformation social media.Predictors Pro-Environmental Behaviours: currently using regression model predict pro-environmental behaviour varying levels capability, motivation, opportunity (.e. COM-B model).Predictors Pro-Environmental Behaviours: currently using regression model predict pro-environmental behaviour varying levels capability, motivation, opportunity (.e. COM-B model).Reflect psychological phenomenon behaviour piqued interest recently studied.Jot potential factors variables believe might influence phenomenon behaviour.Consider factors might integrated regression model. variable choose dependent variable (variable predicting)? variables might serve predictors dependent variable?","code":""},{"path":"introduction-to-regression-analysis.html","id":"overview-of-regression-techniques-covered-in-this-module","chapter":"2 Introduction to Regression analysis","heading":"2.4 Overview of regression techniques covered in this module","text":"handbook cover three main regression techniques:Simple linear regression (basically just fancy correlation)Multiple linear regression (technique required assignment)Binary logistic regression (multiple regression binary, instead continuous, criterion variable)Continue statistics psychology ’ll learn forms regression, regression like, analysis techniques :Ordinal regressionMediation moderationMulti-level modellingStructural equation modelling","code":""},{"path":"simple-linear-regression.html","id":"simple-linear-regression","chapter":"3 Simple linear regression","heading":"3 Simple linear regression","text":"","code":""},{"path":"simple-linear-regression.html","id":"recap-of-correlation","chapter":"3 Simple linear regression","heading":"3.1 Recap of correlation","text":"core, correlation provides measure data points two variables related one another.Positive Correlation: (top left figure) one variable increases, also increases.Negative Correlation: (top right figure) one variable increases, decreases.Correlation: (bottom figure) discernible pattern relationship two variables.strength direction correlation represented correlation coefficient, typically denoted \\(r\\). value \\(r\\) ranges -1 +1.\\(r\\) value closer +1 indicates stronger positive correlation.\\(r\\) value closer -1 indicates stronger negative correlation.\\(r\\) value closer 0 suggests little correlation.","code":""},{"path":"simple-linear-regression.html","id":"correlation-as-a-statistical-test","chapter":"3 Simple linear regression","heading":"3.1.1 Correlation as a Statistical Test","text":"Going beyond visualisation relationships, correlation can also used formal statistical test determine significant linear relationship two variables.conducting correlation test, p-value informs us significance observed correlation coefficient (\\(r\\)). p-value predetermined threshold (commonly 0.05), infer correlation sample likely due random chance, thus, statistically significant relationship two variables.Surface Level Explanation:p-value number 0 1 tells us result experiment likely due chance something going . small p-value (typically less 0.05) suggests result significant just random occurrence.Intermediate Explanation:p-value represents probability observing data (something extreme) given specific null hypothesis true. p-value less pre-decided threshold (like 0.05), reject null hypothesis favour alternative hypothesis. suggests observed data unlikely assumption null hypothesis. However, smaller p-value necessarily mean result \"meaningful\"; just indicates statistically significant.-Depth Explanation:Mathematically, p-value probability observing data extreme , extreme , observed data assumption null hypothesis true. direct measure probability either hypothesis true. Instead, measure extremity data relative specific model.Lower p-values suggest observed data less likely null hypothesis, leading us reject null favour alternative hypothesis. However, crucial understand p-value measure size effect practical significance result. Furthermore, threshold 0.05 common, arbitrary must chosen context caution.Lastly, essential remember p-value contingent correctness underlying statistical model level data meet statistical assumptions. Misunderstandings misuse p-values led various controversies scientific community (see replication crisis). See Lakens (2022) Improving Statistical Inferences comprehensive overview p-values.","code":""},{"path":"simple-linear-regression.html","id":"statistical-assumptions-of-correlation","chapter":"3 Simple linear regression","heading":"3.1.2 Statistical assumptions of correlation","text":"frequentist statistical analysis, often aim use parametric tests statistical assumptions underlying tests met, tests can sensitive smaller effect sizes. correlation analysis, Pearson's correlation commonly used parametric test Spearman's Rank correlation commonly used non-parametric test.experience teaching regression, assumption checks often part statistics confuse students . now, put safely away box, scare first week :-)fully refresh theory behind assumption check aspect next week cover multiple regression.correlation analyse following assumptions checked assessed:Linearity: variables linear relationship, means plot scatterplot, distribution data points roughly form straight line.Linearity: variables linear relationship, means plot scatterplot, distribution data points roughly form straight line.Normality Residuals: data pairs normally distributed, meaning variables analysed approximately normally distributed considered together. checking normality residuals.Normality Residuals: data pairs normally distributed, meaning variables analysed approximately normally distributed considered together. checking normality residuals.Homoscedasticity: spread (variance) residuals constant across values variable x-axis. .e. data points start clustered widen (like funnel) along correlation.Homoscedasticity: spread (variance) residuals constant across values variable x-axis. .e. data points start clustered widen (like funnel) along correlation.Absence Outliers: Outliers can disproportionately influence correlation coefficient. , important check consider impact outliers data. Outliers can checked use boxplot calculated manually.Absence Outliers: Outliers can disproportionately influence correlation coefficient. , important check consider impact outliers data. Outliers can checked use boxplot calculated manually.","code":""},{"path":"simple-linear-regression.html","id":"simple-linear-regression-1","chapter":"3 Simple linear regression","heading":"3.2 Simple linear regression","text":"content sections , likely reflects extent explored correlation first year us. Regression analysis simply extension knowledge. Central understanding concept \"line best fit\".might previously used line visual representation relationship two variables, linear regression, takes pivotal role.","code":""},{"path":"simple-linear-regression.html","id":"the-line-of-best-fit","chapter":"3 Simple linear regression","heading":"3.2.1 The line of best fit","text":"scatter plot , see data points representing hours sleep test performance various participants. Notice data points positively correlated? can capture trend drawing straight line data. line, call \"line best fit,\" gives us simplified representation relationship hours sleep test performance. optimal line best fit one minimises total distance individual data points plot.Even best possible straight line drawn data points, rare line pass exactly every point. vertical distance data point line called \"residual\". every data point, residual difference actual value line predicts value . line best fit job well, residuals quite small, indicating predictions close actual data. However, residuals large, suggests line might capturing relationship two variables adequately.talk residuals, context assumption checks, next chapter.purpose line best fit model relationship test performance number hours slept.model suggest performance test participant gets 7 hours sleep? 100110120130140Find point 7 hours x-axis.Draw finger blueline.Draw finger across y-axis.Take number.test score model suggest participant 7 hours sleep.","code":""},{"path":"simple-linear-regression.html","id":"the-equation-of-a-line","chapter":"3 Simple linear regression","heading":"3.2.2 The equation of a line","text":"Every straight line scatter plot can written simple formula:\\[ Y = mX + c \\]:\\(Y\\) dependent variable.\\(Y\\) dependent variable.\\(X\\) independent variable.\\(X\\) independent variable.\\(c\\) line intersects Y-axis, representing predicted test performance hours sleep .\\(c\\) line intersects Y-axis, representing predicted test performance hours sleep .\\(m\\) slope line, indicating predicted change test performance additional hour sleep.\\(m\\) slope line, indicating predicted change test performance additional hour sleep.make formula previous scatter plot need work much blue line \"goes \" far \"goes along\", line crosses y-axis.scatter plot data axes going zero time. allows us get \\(c\\) value, 50, taking two points line can work \\(m\\) value, case 10 (60/6).give us following equation line:\\[ y = 10x + 50 \\]Look back question . need now sub number 7 get predicted test score: (10*7) + 50 = 120","code":""},{"path":"simple-linear-regression.html","id":"is-this-a-good-model","chapter":"3 Simple linear regression","heading":"3.2.3 Is this a good model?","text":"oft-cited quote sums central truth statistics data modelling: model can capture full intricacy unpredictability real-world phenomena. However, diminish value models. model simplifies complex systems highlights important relationships, can offer invaluable insights guide decision-making.line sleep test score scatter plot () appear quite representative data therefore perhaps fairly good model (long sample representative population want use model future).However, try use relationship participants height test scores model, likely fairly poor model:model derived data, \\(y = -0.05x + 77.89\\), actually give answer close 70 matter individuals height. words, whether taller shorter, model essentially shrugs predicts something close 70 (mean dataset). describe useful model, , spend evening rack try make taller test.can see scatter plot, none numbers equations allow us gauge 'useful' fitting sleep model compared height model. understand model fit need final new concept week, shared variance","code":""},{"path":"simple-linear-regression.html","id":"shared-variance","chapter":"3 Simple linear regression","heading":"3.2.4 Shared Variance","text":"examining relationship two variables, proportion variation one variable can predicted explained variable known shared variance . correlational research, concept crucial tells us well one variable explains variation variable. word useful used scores one variable predict scores variable.good way think visually Venn diagram.value shared variance derived taking square \\(r\\), correlation coefficient, giving us \\(R^2\\) value model. Take instance, sleep model, run pearsons correlation test data find relationship correlation coefficient \\(r\\) = 0.94, squaring give us \\(R^2\\) 0.89 predictor (study hours) outcome (test scores).Another way talk \\(R^2\\) say 89% variance test scores can predicted explained number hours studied. remaining 11% variance due factors included model random error.say two variables share certain percentage variance, indication strength utility relationship. However, high shared variance can promising, essential remember correlation imply causation. underlying factors, third variables, even coincidences create correlations.practical terms, understanding shared variance critical researchers. significant shared variance exists, predictor variable becomes valuable understanding, predicting, even potentially influencing outcome variable. However, unexplained variance might also prompt researchers consider additional predictors factors initially model.Next week start looking multiple regression modelling, name suggest involves multiple variables sharing variance dependent variable.","code":""},{"path":"simple-linear-regression.html","id":"week-1---test-yourself-mcqs","chapter":"3 Simple linear regression","heading":"3.3 Week 1 - Test yourself mcq’s","text":"","code":""},{"path":"jasp-workshop---simple-linear-regression.html","id":"jasp-workshop---simple-linear-regression","chapter":"4 JASP Workshop - Simple linear Regression","heading":"4 JASP Workshop - Simple linear Regression","text":"JASP free, open-source statistical software package user-friendly, point--click interface suitable research psychology. offers wide range statistical analyses, basic descriptive statistics advanced methods like regression ANOVA.JASP available university computers, however, recommend also install personal version laptop desktop computer can continue learning outside class time.JASP can downloaded : www.jasp-stats.org/","code":""},{"path":"jasp-workshop---simple-linear-regression.html","id":"simple-linear-regression---example-analysis","chapter":"4 JASP Workshop - Simple linear Regression","heading":"4.1 Simple linear regression - example analysis","text":"video go analysis answers Simple Linear Regression Exercise 1. like follow along (go exercise first) question sheet data can found Week 1 module area NS5108.","code":""},{"path":"jasp-workshop---simple-linear-regression.html","id":"where-to-click-guide---simple-linear-regression-analysis","chapter":"4 JASP Workshop - Simple linear Regression","heading":"4.2 \"Where to click\" guide - simple linear regression analysis","text":"following step step guide performing correlation simple linear regression analysis JASP. Watch video context related steps.","code":""},{"path":"jasp-workshop---simple-linear-regression.html","id":"correlation","chapter":"4 JASP Workshop - Simple linear Regression","heading":"4.2.1 Correlation","text":"Open JASP.Open JASP.Load Data: click File tab top left select Open. navigate folder containing data file open .Load Data: click File tab top left select Open. navigate folder containing data file open .Visualise data: Identify two variables want run correlation . Click Descriptives move two variables Variables box. , Customizable plots drop tick Scatter plots. may want click none graphs right (make plot clearer). Also change regression line (line best fit) linear.Visualise data: Identify two variables want run correlation . Click Descriptives move two variables Variables box. , Customizable plots drop tick Scatter plots. may want click none graphs right (make plot clearer). Also change regression line (line best fit) linear.Identify outliers: Also customizable plots drop , select boxplots. Tick label outliers show dots outside whiskers box plots. Note interpret outliers.Identify outliers: Also customizable plots drop , select boxplots. Tick label outliers show dots outside whiskers box plots. Note interpret outliers.Calculate correlation coefficient: click Regression -> Correlation top bar. Pick variables interested running correlation . Extract interpret Pearson's \\(r\\) p-value.Calculate correlation coefficient: click Regression -> Correlation top bar. Pick variables interested running correlation . Extract interpret Pearson's \\(r\\) p-value.","code":""},{"path":"jasp-workshop---simple-linear-regression.html","id":"simple-linear-regression-2","chapter":"4 JASP Workshop - Simple linear Regression","heading":"4.2.2 Simple linear regression","text":"Check normality (residuals): Click Regression -> Linear Regression top bar. Pick criterion variable (variable aiming predict) place Dependent variable box. Pick predictor place Covariates box. Plots drop select Residuals histogram. Visually interpret histogram indication assumption check.Check normality (residuals): Click Regression -> Linear Regression top bar. Pick criterion variable (variable aiming predict) place Dependent variable box. Pick predictor place Covariates box. Plots drop select Residuals histogram. Visually interpret histogram indication assumption check.Check Homoscedasticity: Also Plots drop , select Residuals vs. predicted. Visually interpret plot assess Homoscedasticity.Check Homoscedasticity: Also Plots drop , select Residuals vs. predicted. Visually interpret plot assess Homoscedasticity.Extract \\(R^2\\) value: first table Linear Regression section.Extract \\(R^2\\) value: first table Linear Regression section.Determine significance model: can obtained though ANOVA table. F(df,df)=F-value, p=p-value.Determine significance model: can obtained though ANOVA table. F(df,df)=F-value, p=p-value.Extract values model regression equation: H1 intercept = \\(c\\), H1 variable = \\(m\\)Extract values model regression equation: H1 intercept = \\(c\\), H1 variable = \\(m\\)","code":""},{"path":"jasp-workshop---simple-linear-regression.html","id":"jasp-lab-exercises","chapter":"4 JASP Workshop - Simple linear Regression","heading":"4.3 JASP lab exercises","text":"two additional exercises Moodle. exercise question sheet comes dataset answers sheet. Work question check answers answer sheet.","code":""},{"path":"jasp-workshop---simple-linear-regression.html","id":"apa-style-guide","chapter":"4 JASP Workshop - Simple linear Regression","heading":"4.4 APA style guide","text":"example hypothesis correlational analysis:Null Hypothesis (H0): correlation participants' age scores cognitive ability test.Alternative Hypothesis (H1): correlation participants' age scores cognitive ability test.example correlation analysis reported APA style:Pearson correlation conducted assess relationship participants' age scores cognitive ability test. Assumptions checks performed ensure violation assumptions normality residuals, linearity, homoscedasticity. significant negative correlation age cognitive ability scores, r(98) = -.45, p < .001, older participants tending lower scores cognitive ability test. , null hypothesis can rejected.example hypothesis simple linear regression analysis:Null Hypothesis (H0): number study hours significant predictor test scores.Alternative Hypothesis (H1): number study hours significant predictor test scores.example simple linear regression analysis reported APA style:simple linear regression conducted predict test scores based number study hours. assumptions linearity, independence, normality checked met.results indicated significant relationship number study hours test scores, F(1, 98) = 34.5, p < .001. , null hypothesis can rejected R² value .26, indicating approximately 26% variance test scores can explained number study hours.regression equation found :Test Score = 50.2 + 6.7*Study Hours.additional hour study, increase 6.7 points test score. intercept value 50.2 indicates student study (0 hours) expected score 50.2 points test.","code":""},{"path":"multiple-regression.html","id":"multiple-regression","chapter":"5 Multiple regression","heading":"5 Multiple regression","text":"Multiple regression method helps us predict outcome variable based several independent variables. technique tells us variables important predicting outcome, predictor variables interact. building prediction model, multiple regression allows us understand variables connected helps us make powerful data-informed decisions.","code":""},{"path":"multiple-regression.html","id":"shared-variance-with-multiple-variables","chapter":"5 Multiple regression","heading":"5.1 Shared variance with multiple variables","text":"previous chapter simple linear regression, suggested one predictor variable (exercise) shared variance another variable (well-). Visually, can represented using Venn diagram two circles: one exercise one well-.\noverlap two circles represents shared variance, extent variations exercise can explain variations well-. shared variance can represented numerically square correlation coefficient two variables. hypothetical example exercise correlated well-correlation coefficient r=0.307 (.e. moderate-positive correlation) , , can said exercise explains 9.4% variance well-(\\(R^2\\)=0.094)multiple regression analysis, use two independent variables predict value dependent variable. , independent variable may share variance dependent variable, also shares variance among independent variables. Understanding shared variance crucial interpreting results multiple regression analysis.instance, say using three independent variables predict well-: exercise, age, income. variables contribute variance well-.add variables one--one, overlap independent variable circle well-circle represents unique shared variance variable contributes well-.adding samples age data, help us explain well-, see significant correlations three different relationships.\n1. positive correlation exists exercise well-,\n2. negative correlations exist age well-\n3. negative correlation age exercise.\\(R^2\\) derived squaring r value, square negative value, loses negative sign.age exercise now explain variability well-, since also related , variance explain overlaps.Finally, add income, find variable shares variance age well-. Income therefore adds variance explained model also overlapping variance explained ageThe outcome variable add allowed us better explain concept well-. , know person's amount exercise, age, income predict well-greater degree just know amount exercise.important understand Venn diagrams guide offer simplified representation variance explained predictor variables regression model. reality, two predictor variables overlapping variance, shared variance can contribute model individual variables might suggest. occurs due interaction effects, combined influence two predictors can explain variance dependent variable sum individual effects. looking Venn diagrams, remember additional explained variance interactions explicitly depicted, crucial consider interpreting regression results., see later , final \\(R^2\\) greater sum simple (univariate) regressions.","code":""},{"path":"multiple-regression.html","id":"the-regression-equation","chapter":"5 Multiple regression","heading":"5.2 The Regression Equation","text":"probably realised, using Venn diagrams illustrate relationships among multiple variables can get quite confusing, especially numerous variables degree correlation . regression equation comes handy.regression equation mathematical representation relationships among variables multiple regression analysis. shows dependent variable predicted independent variables. abstract form, regression equation can written :\\[ y = \\beta_0 + \\beta_1x_1 + \\beta_2x_2 + \\ldots + \\beta_kx_k + \\varepsilon \\], \\(y\\) dependent variable, \\(x_1\\), \\(x_2\\),...,\\(x_k\\) independent variables (.e. amount exercise, age, income participants), \\(\\beta_0\\) intercept, \\(\\beta_1\\), \\(\\beta_2\\),...,\\(\\beta_k\\) coefficients independent variables, \\(\\varepsilon\\) error term, representing unexplained variability dependent variable (.e. left white space Venn diagram figure ).intercept \\(\\beta_0\\) represents value dependent variable independent variables zero. \\(\\beta_0\\) equivalent intercept, \\(c\\), value equation last week.coefficients (remaining \\(\\beta\\) values) represent average change dependent variable one-unit change respective independent variable, holding variables constant. Just like gradient line \\(m\\) value equation last week. \"...\" \\(k\\)'s just way saying \"add many beta values variables model\".Running regression analysis allowed us substituent numbers coefficients degree left \\(x\\)'s, can use sub data.","code":""},{"path":"multiple-regression.html","id":"interpreting-a-regression-model","chapter":"5 Multiple regression","heading":"5.3 Interpreting a regression model","text":"explain steps running regression model, full, weeks JASP workshop. now, want us just focus interpretation. JASP output model uses variables exercise, age income predict well-scores.break table.","code":""},{"path":"multiple-regression.html","id":"descriptive-statistics","chapter":"5 Multiple regression","heading":"5.3.1 Descriptive statistics","text":"descriptive statistics useful context. detail given can tell dataset (N=1000), well-score 100, exercise variable based number hours exercise week, income £GBP, age years.","code":""},{"path":"multiple-regression.html","id":"model-summary","chapter":"5 Multiple regression","heading":"5.3.2 Model Summary","text":"Model Summary table provides overview overall performance regression model. contains key statistics helps us assess well model fits data.table contains two rows \\(H_0\\) \\(H_1\\). \\(H_0\\) refers null model, model assumes none predictors model effect dependent variable, meaning coefficients predictors equal zero. \\(H_1\\) alternative model, model containing variables. line interests us.main details interest :Adjusted \\(R^2\\) Value: modified version \\(R^2\\) takes account number independent variables model. allows us say much variance dependent variable explained predictor variables.Adjusted \\(R^2\\) Value: modified version \\(R^2\\) takes account number independent variables model. allows us say much variance dependent variable explained predictor variables.RMSE: RMSE stands Root Mean Square Error. measure differences values predicted model values actually observed. RMSE measure spread residuals . words, tells concentrated data around line best fit. used \\(\\varepsilon\\) regression model.RMSE: RMSE stands Root Mean Square Error. measure differences values predicted model values actually observed. RMSE measure spread residuals . words, tells concentrated data around line best fit. used \\(\\varepsilon\\) regression model.often take Adjusted \\(R^2\\) multiple regression \\(R^2\\) simple regression (regression just one predictor variable). well-model, Adjusted \\(R^2\\) 0.469 tells us three variables together explain 46.9% variability well-. pretty good.","code":""},{"path":"multiple-regression.html","id":"anova","chapter":"5 Multiple regression","heading":"5.3.3 ANOVA","text":"ANOVA table provides information overall significance model. shows whether model better predicting dependent variable model independent variables (.e., null model).findings table need reported write-, however, interpret , actually need p-value. significant finding test tells us model significantly better null model.ANOVA stands ANalysis VAriance. come back ANOVA week 4. now, just think slightly fancier t-test, test compares across groups (rather correlates). case comparing null model alternative model seeing significantly different.","code":""},{"path":"multiple-regression.html","id":"coefficients","chapter":"5 Multiple regression","heading":"5.3.4 Coefficients","text":"Finally, understand role variable model need look coefficients table.table provides detailed information individual variables model. includes statistics independent variable intercept model.two columns key understanding model. Unstandardized column p column.Starting p column, probability obtaining t-value extreme one observed null hypothesis true. small p-value indicates variable plays statistically significant role model. case include variable related dependent variable variance explains accounted variables model. cases, p-value 0.05. p-value <.001 three variables indicates relevant include model.values Unstandardized column correspond \\(\\beta\\) values regression equation. play role gradient line best fit simple regression last week. represent absolute change dependent variable one-unit change independent variable, holding variables constant.model, table tells us :every 1 hour increase exercise week, well-increases 1.88 points.every 1 year ageing, well-decreases 1.09 points.every £1 income, well-increased 0.001 points.last finding intuitive , makes sense convert income values 1000's pounds (.e. someone earns £32500 year can said earn 32.5 thousand pounds year). need divide income values 1000 run model .gives us :every £1000 income, well-increases 1.35 points.","code":""},{"path":"multiple-regression.html","id":"building-our-regression-equation-from-the-model","chapter":"5 Multiple regression","heading":"5.4 Building our regression equation from the model","text":"can now start building regression equation. three variables predicting well-need fill \\(\\beta\\) values \\(\\varepsilon\\) following equation.\\[ Wellbeing = \\beta_0 + \\beta_1income + \\beta_2age + \\beta_3exercise + \\varepsilon \\]\\(\\beta_0\\) = unstandardized (beta) value intercept \\(H_1\\) = 35.25\\(\\beta_1\\) - \\(\\beta_3\\) = unstandardized (beta) value three variables = 1.35, -1.09 1.88\\(\\varepsilon\\) = Root Mean Square Error (RMSE) \\(H_1\\) = 15.7This give us following regression equation:\\[ Wellbeing = 35.25 + 1.35income -1.09age + 1.88exercise + 15.7\\]equation, knew individual's income, age much exercise engaged per week estimate well-fairly high degree accuracy.Alongside equation important note Adjusted \\(R^2\\) 0.469, indicate means half variability well-explained variables included model.","code":""},{"path":"multiple-regression.html","id":"so-what","chapter":"5 Multiple regression","heading":"5.5 So what?","text":"point work? Well, wanting increase well-local community finding might put putting money community exercise classes. likely benefits intervention, many hours week , based data, 1.88 point increase well-(scale 100) extra hour exercise might cost-effective way spending limited pool money., like can stop someone ageing, increase income. Perhaps research compares effects , example, exercise, mindfulness diet, controlling demographic factors, useful inform type intervention might cost-effective.","code":""},{"path":"multiple-regression.html","id":"week-2---test-yourself-mcqs","chapter":"5 Multiple regression","heading":"5.6 Week 2 - Test yourself mcq’s","text":"multiple regression?\n\nUsing single categorical variable predict value dependent variable.method helps predict outcome variable based one independent variable.method helps predict outcome variable based several independent variables.measure association two variables.\nregression equation?\n\ngraphical representation relationships among variables.mathematical calculation shared variance.mathematical representation relationships among variables multiple regression analysis.empirical observation relationships among variables.\nregression equation, β values represent?\n\ndependent variable.coefficients independent variables.error term.independent variables.\nvalues Unstandardized column coefficients table represent?\n\nshared variance variables.average change dependent variable one-unit change respective independent variable, holding variables constant.correlation coefficient variables.absolute value correlation coefficient variables.\nAdjusted \\(R^2\\) value tell us multiple regression analysis?\n\nstrength linear relationship dependent variable independent variable.shared variance among independent variables.percentage variability dependent variable explained predictor variables.effect size independent variables dependent variable.\n","code":""},{"path":"statistical-assumption-checks-for-multiple-regression.html","id":"statistical-assumption-checks-for-multiple-regression","chapter":"6 Statistical assumption checks for multiple regression","heading":"6 Statistical assumption checks for multiple regression","text":"point studies, important understand assess report statistical assumptions underlying regression analysis. However, advanced stages career learn address violations assumptions.now, just interpret report assumptions. results deviate greatly assumptions, important report deviations state findings \"taken caution\".key assumptions multiple regression check :","code":""},{"path":"statistical-assumption-checks-for-multiple-regression.html","id":"check-for-linearity","chapter":"6 Statistical assumption checks for multiple regression","heading":"6.1 Check for Linearity","text":"assumption linearity states relationship independent dependent variables linear. can check visually examining scatter plots independent variables dependent variable.","code":""},{"path":"statistical-assumption-checks-for-multiple-regression.html","id":"check-for-multicollinearity","chapter":"6 Statistical assumption checks for multiple regression","heading":"6.2 Check for Multicollinearity","text":"Multicollinearity occurs two independent variables regression model closely related, making difficult disentangle individual effects dependent variable. can lead unstable coefficient estimates, small changes data can result significant changes estimates. can assess multicollinearity creating correlation matrix independent variables looking variables correlation coefficient greater 0.7 less -0.7. However, strict rule, just indication strong correlation.table , suppose use five personality constructs predict behaviour, recidivism. Checking correlation coefficients, largest value -0.368, indicating multicollinearity likely issue case. mindful confuse correlation coefficients p-values, easy mistake make.multicollinearity can make interpretation challenging, necessarily deal-breaker. cases, focus may predicting outcome rather interpreting individual contributions predictor. -depth discussion multicollinearity implications see Vatcheva et al (2016).","code":""},{"path":"statistical-assumption-checks-for-multiple-regression.html","id":"check-for-outliers","chapter":"6 Statistical assumption checks for multiple regression","heading":"6.3 Check for Outliers","text":"Outliers data points differ significantly observations. can detected various methods. boxplot, outliers typically displayed individual points outside whiskers, extend first third quartiles (Q1 Q3) Q1 - 1.5 * IQR (interquartile range) Q3 + 1.5 * IQR, respectively (see link full explanation read boxplot).JASP can automatically identify outliers boxplots, making easier spot . However, addressing outliers often contentious issue treatment can significant impact results statistical analysis. decision keep remove outliers depends multiple factors.First, important consider context data. Outliers result measurement errors, data entry errors, random anomalies. However, also represent genuine extreme values offer valuable insights. example, study wealth distribution, billionaires outliers real-world phenomenon might important research.Secondly, outliers can heavily influence data assumptions, linearity, normality residuals, homoscedasticity. crucial evaluate whether outliers affecting assumptions justify removal retention. , fact, can away addressing violations assumptions listed chapter.Thirdly, outliers can disproportionately affect key statistical measures like mean standard deviation. easy fall trap removing outliers significant results appears. kind practice may fall grey area academic misconduct discussed first year, known Questionable Research Practices.Ultimately, decision handle outliers involves balance statistical judgment domain expertise. necessary ensure decision involves transparently reporting justifying decisions.","code":""},{"path":"statistical-assumption-checks-for-multiple-regression.html","id":"checks-of-residuals","chapter":"6 Statistical assumption checks for multiple regression","heading":"6.4 Checks of residuals","text":"last two assumption checks require examination residual. Residuals fundamental concept regression analysis, representing difference observed predicted values dependent variable. simple regression, visualised predicted value line best fit, observed value just data point relationship.observation, residual calculated subtracting predicted value observed value. simple linear regression, one independent variable, residual observation distance data point regression line. multiple regression, distance observation regression plane.goal regression analysis minimize residuals, words, make predicted values close possible observed values. Residuals can used evaluate fit regression model, detect outliers, check violations assumptions regression.","code":""},{"path":"statistical-assumption-checks-for-multiple-regression.html","id":"check-for-normality-of-residuals","chapter":"6 Statistical assumption checks for multiple regression","heading":"6.4.1 Check for Normality of Residuals","text":"assumption normality residuals important hypothesis testing linear regression. ensures standard errors coefficients unbiased significant testing coefficients valid. , turn, helps us make valid inferences relationships variables.contrast, checking normality individual variables required linear regression. Instead, focus distribution residuals, normally distributed model's assumptions met. residuals represent differences observed predicted values dependent variable, distribution tells us model's fit relationships variables.working program can calculate residuals, can check normality residuals using Shaperio Wilks test assessing skewness kurtosis. JASP means checking normality residuals normality residuals plot option.","code":""},{"path":"statistical-assumption-checks-for-multiple-regression.html","id":"check-for-homoscedasticity","chapter":"6 Statistical assumption checks for multiple regression","heading":"6.4.2 Check for Homoscedasticity","text":"Homoscedasticity, word strikes fear undergrad (postgrad) psychology students throughout land, complicated sounds.\"Homos\": Greek \"\" \"equal.\" context homoscedasticity, refers equality sameness variances.\"Homos\": Greek \"\" \"equal.\" context homoscedasticity, refers equality sameness variances.\"Skedasis\": Greek word related concept dispersion spreading . statistics, associated variance scatter data points.\"Skedasis\": Greek word related concept dispersion spreading . statistics, associated variance scatter data points.scatter plots demonstrate data might look. Heteroscedasticity (.e. different \"spreadness\") means line best fit becomes less reliable different points model.context, looking equal distribution data points along line best fit, avoiding funnel-shaped pattern. dealing regression analyses involve two predictor variables, often feasible visualise data. cases, plot predicted variables residuals can used check homoscedasticity. plot, , , looking absence funnel shape points.check can also performed using z-scores predicted values residuals; level line context indicate homoscedasticity (uniform spread residuals). method used software like SPSS checking homoscedasticity, may see guides talking read wider topic.","code":""},{"path":"jasp-workshop---multiple-regression.html","id":"jasp-workshop---multiple-regression","chapter":"7 JASP Workshop - Multiple regression","heading":"7 JASP Workshop - Multiple regression","text":"JASP free, open-source statistical software package user-friendly, point--click interface suitable research psychology. offers wide range statistical analyses, basic descriptive statistics advanced methods like regression ANOVA.JASP available university computers, however, recommend also install personal version laptop desktop computer can continue learning outside class time.JASP can downloaded : www.jasp-stats.org/","code":""},{"path":"jasp-workshop---multiple-regression.html","id":"multiple-regression---example-analysis","chapter":"7 JASP Workshop - Multiple regression","heading":"7.1 Multiple regression - Example analysis","text":"video go analysis answers Multiple Regression Exercise 1. like follow along (go exercise first) question sheet data can found Week 2 module area NS5108.","code":""},{"path":"jasp-workshop---multiple-regression.html","id":"where-to-click-guide---multiple-regression","chapter":"7 JASP Workshop - Multiple regression","heading":"7.2 \"Where to click\" guide - Multiple Regression","text":"Open JASP.Open JASP.Load Data: click File tab top left select Open. navigate folder containing data file open .Load Data: click File tab top left select Open. navigate folder containing data file open .Identify variable predictors dependent variable (variable aiming predict).Identify variable predictors dependent variable (variable aiming predict).Check linear relationships predictor variables: Click Regression -> Correlation top bar. Move predictor variables dependent variable Variables Box. Click Scatter plots options. Visually interpret Correlation plots determine predictor variables linear relationship dependent variable.Check linear relationships predictor variables: Click Regression -> Correlation top bar. Move predictor variables dependent variable Variables Box. Click Scatter plots options. Visually interpret Correlation plots determine predictor variables linear relationship dependent variable.Check multicollinearity: Within results section step 3 check correlation table. Interpret correlation coefficients predictor variables large enough indicate issue multicollinearity.Check multicollinearity: Within results section step 3 check correlation table. Interpret correlation coefficients predictor variables large enough indicate issue multicollinearity.Check normality (residuals): Click Regression -> Linear Regression top bar. Pick dependent variable place Dependent variable box. Pick predictor variables place Covariates box. Plots drop select Residuals histogram. Visually interpret histogram indication assumption check.Check normality (residuals): Click Regression -> Linear Regression top bar. Pick dependent variable place Dependent variable box. Pick predictor variables place Covariates box. Plots drop select Residuals histogram. Visually interpret histogram indication assumption check.Check Homoscedasticity: Also Plots drop , select Residuals vs. predicted. Visually interpret plot assess Homoscedasticity.Check Homoscedasticity: Also Plots drop , select Residuals vs. predicted. Visually interpret plot assess Homoscedasticity.Extract Adjusted \\(R^2\\) value: first table Linear Regression section.Extract Adjusted \\(R^2\\) value: first table Linear Regression section.Determine significance model: can obtained though ANOVA table. F(df,df)=F-value, p=p-value.Determine significance model: can obtained though ANOVA table. F(df,df)=F-value, p=p-value.Extract values model regression equation: unstandardized values coefficients table. See report findings.Extract values model regression equation: unstandardized values coefficients table. See report findings.","code":""},{"path":"jasp-workshop---multiple-regression.html","id":"jasp-lab-exercises-1","chapter":"7 JASP Workshop - Multiple regression","heading":"7.3 JASP lab exercises","text":"two additional exercises Moodle. exercise question sheet comes dataset answers sheet. Work question check answers answer sheet.","code":""},{"path":"jasp-workshop---multiple-regression.html","id":"apa-style-guide-for-multiple-regression","chapter":"7 JASP Workshop - Multiple regression","heading":"7.4 APA Style Guide for Multiple Regression","text":"","code":""},{"path":"jasp-workshop---multiple-regression.html","id":"hypothesis-for-multiple-regression-analysis","chapter":"7 JASP Workshop - Multiple regression","heading":"7.4.1 Hypothesis for Multiple Regression Analysis","text":"Null Hypothesis (H0): Neither self-esteem study hours significant predictors academic performance.Alternative Hypothesis (H1): least one self-esteem study hours significant predictor academic performance.","code":""},{"path":"jasp-workshop---multiple-regression.html","id":"reporting-multiple-regression-in-apa-style","chapter":"7 JASP Workshop - Multiple regression","heading":"7.4.2 Reporting Multiple Regression in APA Style","text":"multiple linear regression conducted explore impact self-esteem study hours academic performance. Assumptions linearity, independence, multicollinearity, normality checked met.multiple regression model significantly predicted academic performance, F(2, 97) = 36.8, p < .001, \\(R^2\\) = .43.regression equation found : Academic Performance = 45.2 + 4.1 * Self-Esteem + 5.2 * Study Hours.self-esteem study hours significantly added prediction academic performance. Specifically, self-esteem significant predictor, t(97) = 2.9, p = .005, contributed increase 4.1 points every unit increase self-esteem. Study hours also significant predictor, t(97) = 5.1, p < .001, contributed increase 5.2 points every additional hour spent studying.Overall, model explained approximately 43% variance academic performance (R² = .43)., null hypothesis can rejected, indicating least one predictors significantly impacts academic performance.","code":""},{"path":"logistic-regression.html","id":"logistic-regression","chapter":"8 Logistic regression","heading":"8 Logistic regression","text":"[Chapter currently construction]chapter look final regression technique, logistic regression. Unlike linear regression, predicts continuous outcome variable based one predictor variables, logistic regression used outcome variable categorical. common form logistic regression binary logistic regression, outcome limited two categories Yes , Diagnosis Diagnosis, 1 0.instance, imagine interested exploring factors predict whether individuals likely high blood pressure. linear regression help predict something continuous like systolic blood pressure measurments, logistic regression help predict whether someone likely diagnosis hypertention (high blood pressure) .Logistic regression uses mathematical function transforms linear input probability 0 1. logistic function \"S\" shape, allowing smoothly transition two extremes.","code":""},{"path":"logistic-regression.html","id":"modelling-a-logistic-function","chapter":"8 Logistic regression","heading":"8.1 Modelling a logistic function","text":"S-curve logistic regression essentially plotting probability event occurring across range predictor variable. example plotted stress level (scale 0 50) probability individual relapsing particular damaging behaviour (.e, drug taking, smoking etc).curve add relationship works similarly line best fit datapoints first used simple regression chapters. want work chance relaps individual scores 30 stress variable need trace point 30 line read corresponding y-axis point. case value around 0.6 indicating , according model, scores 30 scale indicates individual 85% estimated probability experiencing relapse.","code":""},{"path":"logistic-regression.html","id":"understanding-odds-ratios-in-the-context-of-logistic-regression","chapter":"8 Logistic regression","heading":"8.2 Understanding odds ratios in the context of logistic regression","text":"previous section talked probability event (probabilities 0 1) however can also talk data terms odds, particularly odds relaps event increase function increase stress variable.Odds ratios calculated coefficients (\\(\\beta\\)) logistic regression model (JASP calculates automatically tick odds ration button wont go maths ). odds ratio greater 1 indicates predictor variable increases, odds outcome occurring also increase. Conversely, odds ratio less 1 indicates predictor increases, odds outcome occurring decrease.case current model odds ratio 1.29 indicating every unit increase stress chance relaps increases 29%.Possible data set: https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0255683#sec019[Chapter currently construction]","code":""},{"path":"further-reading.html","id":"further-reading","chapter":"9 further reading","heading":"9 further reading","text":"Beyond multiple linear regression: https://bookdown.org/roback/bookdown-BeyondMLR/Introduction modern statistics: https://openintro-ims.netlify.app/","code":""}]
