[{"path":"index.html","id":"welcome","chapter":"1 Welcome","heading":"1 Welcome","text":"Welcome R Handbook NS5108","code":""},{"path":"introduction.html","id":"introduction","chapter":"2 Introduction","heading":"2 Introduction","text":"Regression analysis powerful statistical tool investigates relationships variables. core, seeks understand quantify one variable (criterion variable) changes response another several others (predictor variables). merely determining singular correlation, regression analysis offers nuanced lens, enabling researchers predict outcomes uncover sophisticated patterns embedded within datasets. method provides richer understanding multifaceted interactions underpin psychological phenomena.","code":""},{"path":"introduction.html","id":"data-driven-decision-making.","chapter":"2 Introduction","heading":"2.1 Data-driven decision making.","text":"2011 film \"Moneyball\" based true story Oakland Athletics baseball team's 2002 season. general manager, Billy Beane (played Brad Pitt film), faced significant problem: limited budget put together winning team. Rather relying traditional baseball scouting methods, often depended heavily scouts' intuitions prone various biases, Beane employed skills young Yale economics graduate named Peter Brand (played Jonah Hill). Brand used statistical analysis evaluate players' values.traditional method valuing players subjective. Scouts often looked physique players, style, moved, even things like attractiveness girlfriends indicator confidence. Beane Brand shifted focus objective evidence, including statistics.One major statistics Brand focused player's -base percentage. metric looks often batter reaches base, whether hit, walk, hit pitch. Rather paying high prices stars, recruit undervalued players good OBP, lead runs , consequently, wins.core, analytics used \"Moneyball\" predicting runs, importantly, wins. Using regression analysis, determine statistics strongly correlated creating runs. understanding leads runs, use build model aid player acquisition decisions.film highlights tensions arise data-driven metrics clash entrenched traditional norms. Yet, time progresses, efficacy analytical techniques becomes increasingly evident. Today, rarity encounter professional sports team incorporate form statistical analysis strategy decision-making processes, showcasing undeniable impact relevance regression modern world.","code":""},{"path":"introduction.html","id":"further-real-world-examples","chapter":"2 Introduction","heading":"2.2 Further real world examples","text":"course, ’s just world sports taken advantage regression analysis inform decision making. examples everyday life regression analysis played role.Streaming Services Recommendations: probably use platforms like Netflix, Spotify, YouTube. platforms utilise regression analysis predict shows, songs, videos might like based past behaviour behaviour others similar tastes.Streaming Services Recommendations: probably use platforms like Netflix, Spotify, YouTube. platforms utilise regression analysis predict shows, songs, videos might like based past behaviour behaviour others similar tastes.Predicting Box-office Income Different Forms Advertising: Film producers often use regression analyses gauge adverts, TV spots social media campaigns, influence cinema ticket sales, optimising advertising budgets upcoming films based insights.Predicting Box-office Income Different Forms Advertising: Film producers often use regression analyses gauge adverts, TV spots social media campaigns, influence cinema ticket sales, optimising advertising budgets upcoming films based insights.Price Sensitivity Public Particular Product: coffee chain might employ regression analysis determine optimal price lattes, balancing customer demand profit margins, ensuring consistent footfall profitability.Price Sensitivity Public Particular Product: coffee chain might employ regression analysis determine optimal price lattes, balancing customer demand profit margins, ensuring consistent footfall profitability.Predicted Crop Yield Based Weather Conditions: Regression analysis used extensively farming predict something like corn yields based weather forecasts, adjusting farming strategies anticipation conditions like particularly dry summer.Predicted Crop Yield Based Weather Conditions: Regression analysis used extensively farming predict something like corn yields based weather forecasts, adjusting farming strategies anticipation conditions like particularly dry summer.","code":""},{"path":"introduction.html","id":"use-of-regression-analysis-in-psychology","chapter":"2 Introduction","heading":"2.3 Use of regression analysis in psychology","text":"Regression analysis also cornerstone psychological research, allows psychologists simultaneously explore dissect influence numerous variables single outcome variable. comprehensive approach indispensable field like psychology, behaviours mental processes often outcome web interconnected variables.instance:Cognitive Development Children: Researchers might use regression analysis determine variables hours sleep, nutritional intake, classroom environment influence cognitive development scores children.Cognitive Development Children: Researchers might use regression analysis determine variables hours sleep, nutritional intake, classroom environment influence cognitive development scores children.Efficacy Therapeutic Interventions: clinical psychology, regression might employed predict effectiveness different therapeutic interventions, considering variables duration therapy, patient's initial symptom severity, therapist experience.Efficacy Therapeutic Interventions: clinical psychology, regression might employed predict effectiveness different therapeutic interventions, considering variables duration therapy, patient's initial symptom severity, therapist experience.Predictors Job Satisfaction: Organizational psychologists use regression determine factors (e.g., salary, working hours, team dynamics, leadership style) significant predictors job satisfaction among employees.Predictors Job Satisfaction: Organizational psychologists use regression determine factors (e.g., salary, working hours, team dynamics, leadership style) significant predictors job satisfaction among employees.Influence Social Behaviours: Social psychologists might employ regression analysis understand various factors like media exposure, peer influence, past experiences predict certain social behaviours attitudes, aggression altruism.Influence Social Behaviours: Social psychologists might employ regression analysis understand various factors like media exposure, peer influence, past experiences predict certain social behaviours attitudes, aggression altruism.Reflect psychological phenomenon behaviour piqued interest recently studied.Jot potential factors variables believe might influence phenomenon behaviour.Consider factors might integrated regression model. variable choose criterion variable (one ’ll predicting)? ones might serve predictors?","code":""},{"path":"introduction.html","id":"overview-of-regression-techniques-covered-in-this-module","chapter":"2 Introduction","heading":"2.4 Overview of regression techniques covered in this module","text":"module cover three main regression techniques:Simple linear regression (basically just fancy correlation)Multiple linear regression (technique required assignment)Binary logistic regression (multiple regression binary, instead continuous, criterion variable)Continue statistics psychology ’ll learn forms regression, regression like, analysis techniques :Ordinal regressionMediation moderationMulti-level modellingStructural equation modelling","code":""},{"path":"simple-linear-regression.html","id":"simple-linear-regression","chapter":"3 Simple linear regression","heading":"3 Simple linear regression","text":"","code":""},{"path":"simple-linear-regression.html","id":"recap-of-correlation","chapter":"3 Simple linear regression","heading":"3.1 Recap of correlation","text":"core, correlation provides measure data points two variables related one another.Positive Correlation: (top left figure) one variable increases, also increases. Similarly, one decreases, also decreases.Negative Correlation: (top right figure) one variable increases, decreases, vice versa.Correlation: (bottom figure) discernible pattern relationship two variables.strength direction correlation represented correlation coefficient, typically denoted \\(r\\). value \\(r\\) ranges -1 +1.\\(r\\) value close +1 indicates strong positive correlation.\\(r\\) value close -1 indicates strong negative correlation.\\(r\\) value close 0 suggests little correlation.","code":""},{"path":"simple-linear-regression.html","id":"correlation-as-a-statistical-test","chapter":"3 Simple linear regression","heading":"3.1.1 Correlation as a Statistical Test","text":"Going beyond visualisation relationships, correlation can also used formal statistical test determine significant linear relationship two variables.conducting correlation test, tests p-value informs us significance observed correlation coefficient (\\(r\\)). p-value predetermined threshold (commonly 0.05), infer correlation sample likely due random chance, thus, statistically significant relationship two variables.Surface Level Explanation:p-value number 0 1 tells us result experiment likely due chance something going . small p-value (typically less 0.05) suggests result significant just random occurrence.Intermediate Explanation:p-value represents probability observing data (something extreme) given specific null hypothesis true. p-value less pre-decided threshold (like 0.05), reject null hypothesis favour alternative hypothesis. suggests observed data unlikely assumption null hypothesis. However, smaller p-value necessarily mean result meaningful; just indicates statistically significant.-Depth Explanation:Mathematically, p-value probability observing data extreme , extreme , observed data assumption null hypothesis true. direct measure probability either hypothesis true. Instead, measure extremity data relative specific model.Lower p-values suggest observed data less likely null hypothesis, leading us reject null favour alternative hypothesis. However, crucial understand p-value measure size effect practical significance result. Furthermore, threshold 0.05 common, arbitrary must chosen context caution.Lastly, essential remember p-value contingent correctness underlying statistical model level data meet statistcial assumptions. Misunderstandings misuse p-values led various controversies scientific community (see replication crisis). See Lakens (2022) Improving Statistical Inferences comprehensive overview p-values.","code":""},{"path":"simple-linear-regression.html","id":"statistical-assumptions-of-correlation","chapter":"3 Simple linear regression","heading":"3.1.2 Statistical assumptions of correlation","text":"frequentist statistical analysis, often aim use parametric tests statistical assumptions underlying tests met, tests can sensitive effects assumptions hold. correlation analysis, Pearson's correlation commonly used parametric test Spearman's Rank correlation commonly used non-parametric test.Assumption checks often part statistics confuse students . now, put safely away box, scare first week :-)fully refresh theory behind assumption check aspect next week cover multiple regression.correlation analyse following assumptions checked assessed:Linearity: variables linear relationship, means plot scatterplot, distribution data points roughly form straight line.Linearity: variables linear relationship, means plot scatterplot, distribution data points roughly form straight line.(Bivariate) Normality: data pairs bivariately normally distributed, meaning variables analysed approximately normally distributed considered together. checking normality residuals.(Bivariate) Normality: data pairs bivariately normally distributed, meaning variables analysed approximately normally distributed considered together. checking normality residuals.Homoscedasticity: spread (variance) residuals constant across values variable x-axis. .e. data points start clustered widen (like funnel) along correlation.Homoscedasticity: spread (variance) residuals constant across values variable x-axis. .e. data points start clustered widen (like funnel) along correlation.Absence Outliers: Outliers can disproportionately influence correlation coefficient. , important check consider impact outliers data. Outliers can checked use boxplot calculated manually.Absence Outliers: Outliers can disproportionately influence correlation coefficient. , important check consider impact outliers data. Outliers can checked use boxplot calculated manually.","code":""},{"path":"simple-linear-regression.html","id":"simple-linear-regression-1","chapter":"3 Simple linear regression","heading":"3.2 Simple linear regression","text":"content sections , likely reflects extent explored correlation first year us. Regression analysis simply extension concepts. Central understanding \"line best fit.\"might previously used line visual representation relationship two variables, linear regression, takes pivotal role.","code":""},{"path":"simple-linear-regression.html","id":"the-line-of-best-fit","chapter":"3 Simple linear regression","heading":"3.2.1 The line of best fit","text":"scatter plot , see data points representing hours sleep test performance various participants. Notice data points positively correlated? can capture trend drawing straight line data. line, call \"line best fit,\" gives us simplified representation relationship hours sleep test performance.optimal line best fit one minimises total distance individual data points plot.Even best possible straight line drawn data points, rare line pass exactly every point. vertical distance data point line called \"residual\". every data point, residual difference actual value line predicts value . line best fit job well, residuals quite small, indicating predictions close actual data. However, residuals large, suggests line might capturing relationship two variables adequately.talk residuals, context assumption checks, next chapter.purpose line best fit model relationship test performance number hours slept.model suggest performance test participant gets 7 hours sleep? 100110120130140Find point 7 hours x-axis.Draw finger blueline.Draw finger across y-axis.Take number.test score model suggest participant 7 hours sleep.","code":""},{"path":"simple-linear-regression.html","id":"the-equasion-of-a-line","chapter":"3 Simple linear regression","heading":"3.2.2 The equasion of a line","text":"Every straight line scatter plot can written simple formula:\\[ Y = mX + c \\]:\\(Y\\) dependent variable.\\(Y\\) dependent variable.\\(X\\) independent variable.\\(X\\) independent variable.\\(c\\) line intersects Y-axis, representing predicted test performance hours sleep .\\(c\\) line intersects Y-axis, representing predicted test performance hours sleep .\\(m\\) slope line, indicating predicted change test performance additional hour sleep.\\(m\\) slope line, indicating predicted change test performance additional hour sleep.make formula previous scatter plot need work much blue line \"goes \" far \"goes along\", line crosses y-axis.scatter plot data axes going zero time. allows us get \\(c\\) value, 50, taking two points line can work \\(m\\) value, case 10 (60/6).give us following equasion line:\\[ y = 10x + 50 \\]Look back question . need now sub number 7 get predicted test score: (10*7) + 50 = 120","code":""},{"path":"simple-linear-regression.html","id":"is-this-a-good-model","chapter":"3 Simple linear regression","heading":"3.2.3 Is this a good model?","text":"oft-cited quote sums central truth statistics data modelling: model can capture full intricacy unpredictability real-world phenomena. However, diminish value models. model simplifies complex systems highlights important relationships, can offer invaluable insights guide decision-making.line sleep test score scatter plot () appear quite representative data therefore perhaps fairly good model (long sample representative population want use model future).However, try use relationship participants height test scores model, likely fairly poor model:model derived data, \\(y = -0.05x + 77.89\\), actually give answer close 70 matter individuals height. words, whether taller shorter, model essentially shrugs predicts something close 70 (mean dataset). describe useful model, , spend evening rack try make taller test.can see scatter plot, none numbers equations allow us gauge 'useful' fitting sleep model compared height model. understand model fit need final new concept week, shared variance","code":""},{"path":"simple-linear-regression.html","id":"shared-variance","chapter":"3 Simple linear regression","heading":"3.2.4 Shared Variance","text":"examining relationship two variables, proportion variation one variable can predicted explained variable known shared variance . correlational research, concept crucial tells us well one variable explains variation variable. word useful used scores one variable predict scores variable.good way think visually Venn diagram.value shared variance derived taking square \\(r\\), correlation coefficient, giving us \\(R^2\\) value model. Take instance, sleep model, run pearsons correlation test data find relationship correlation coefficient \\(r\\) = 0.94, squaring give us \\(R^2\\) 0.89 predictor (study hours) outcome (test scores).Another way talk \\(R^2\\) say 89% variance test scores can predicted explained number hours studied. remaining 11% variance due factors included model random error.say two variables share certain percentage variance, indication strength utility relationship. However, high shared variance can promising, essential remember correlation imply causation. underlying factors, third variables, even coincidences create correlations.practical terms, understanding shared variance critical researchers. significant shared variance exists, predictor variable becomes valuable understanding, predicting, even potentially influencing outcome variable. However, unexplained variance might also prompt researchers consider additional predictors factors initially model.Next week start looking multiple regression modeling, name suggest involves multiple variables sharing variance dependent variable.","code":""},{"path":"simple-linear-regression.html","id":"week-1---test-yourself-mcqs","chapter":"3 Simple linear regression","heading":"3.3 Week 1 - Test yourself mcq’s","text":"","code":""},{"path":"week-1---jasp-workshop---simple-linear-regression.html","id":"week-1---jasp-workshop---simple-linear-regression","chapter":"4 Week 1 - JASP Workshop - Simple linear Regression","heading":"4 Week 1 - JASP Workshop - Simple linear Regression","text":"JASP free, open-source statistical software package user-friendly, point--click interface suitable research psychology. offers wide range statistical analyses, basic descriptive statistics advanced methods like regression ANOVA.JASP available university computers, however, recommend also install personal version laptop desktop computer can continue learning outside class time.JASP can downloaded : www.jasp-stats.org/","code":""},{"path":"week-1---jasp-workshop---simple-linear-regression.html","id":"simple-linear-regression---example-analysis","chapter":"4 Week 1 - JASP Workshop - Simple linear Regression","heading":"4.1 Simple linear regression - example analysis","text":"video go analysis answers Simple Linear Regression Exercise 1. like follow along (go exercise first) question sheet data can found Week 1 module area NS5108.","code":""},{"path":"week-1---jasp-workshop---simple-linear-regression.html","id":"where-to-click-guide---simple-linear-regression-analysis","chapter":"4 Week 1 - JASP Workshop - Simple linear Regression","heading":"4.2 \"Where to click\" guide - simple linear regression analysis","text":"following step step guide performing correlation simple linear regression analysis JASP. Watch video context related steps.","code":""},{"path":"week-1---jasp-workshop---simple-linear-regression.html","id":"correlation","chapter":"4 Week 1 - JASP Workshop - Simple linear Regression","heading":"4.2.1 Correlation","text":"Open JASP.Open JASP.Load Data: click File tab top left select Open. navigate folder containing data file open .Load Data: click File tab top left select Open. navigate folder containing data file open .Visualise data: Identify two variables want run correlation . Click Descriptives move two variables Variables box. , Customizable plots drop tick Scatter plots. may want click none graphs right (make plot clearer). Also change regression line (line best fit) linear.Visualise data: Identify two variables want run correlation . Click Descriptives move two variables Variables box. , Customizable plots drop tick Scatter plots. may want click none graphs right (make plot clearer). Also change regression line (line best fit) linear.Identify outliers: Also customizable plots drop , select boxplots. Tick label outliers show dots outside wihiskers box plots. Note interpret outliers.Identify outliers: Also customizable plots drop , select boxplots. Tick label outliers show dots outside wihiskers box plots. Note interpret outliers.Calculate correlation coefficent: click Regression -> Correlation top bar. Pick variables interested running correlation . Extract interpret Pearson's \\(r\\) p-value.Calculate correlation coefficent: click Regression -> Correlation top bar. Pick variables interested running correlation . Extract interpret Pearson's \\(r\\) p-value.","code":""},{"path":"week-1---jasp-workshop---simple-linear-regression.html","id":"simple-linear-regression-2","chapter":"4 Week 1 - JASP Workshop - Simple linear Regression","heading":"4.2.2 Simple linear regression","text":"Check normality (residuals): Click Regression -> Linear Regression top bar. Pick criterion variable (variable aiming predict) place Dependent variable box. Pick predictor place Covariates box. Plots drop select Residuals histogram. Visually interpret histogram indication assumption check.Check normality (residuals): Click Regression -> Linear Regression top bar. Pick criterion variable (variable aiming predict) place Dependent variable box. Pick predictor place Covariates box. Plots drop select Residuals histogram. Visually interpret histogram indication assumption check.Check Homoscedasiticity: Also Plots drop , select Residuals vs. predicted. Visually interpret plot assess Homoscedasiticity.Check Homoscedasiticity: Also Plots drop , select Residuals vs. predicted. Visually interpret plot assess Homoscedasiticity.Extract \\(R^2\\) value: first table Linear Regression section.Extract \\(R^2\\) value: first table Linear Regression section.Determine significance model: can obtained though ANOVA table. F(df,df)=F-value, p=p-value.Determine significance model: can obtained though ANOVA table. F(df,df)=F-value, p=p-value.Extract values model regression equation: H1 intercept = \\(c\\), H1 variable = \\(m\\)Extract values model regression equation: H1 intercept = \\(c\\), H1 variable = \\(m\\)","code":""},{"path":"week-1---jasp-workshop---simple-linear-regression.html","id":"jasp-lab-exercises","chapter":"4 Week 1 - JASP Workshop - Simple linear Regression","heading":"4.3 JASP lab exercises","text":"two additional exercises Moodle. exercise question sheet comes dataset answers sheet. Work question check answers answer sheet.","code":""},{"path":"week-1---jasp-workshop---simple-linear-regression.html","id":"apa-style-guide","chapter":"4 Week 1 - JASP Workshop - Simple linear Regression","heading":"4.4 APA style guide","text":"example hypothesis correlational analysis:Null Hypothesis (H0): correlation participants' age scores cognitive ability test.Alternative Hypothesis (H1): correlation participants' age scores cognitive ability test.example correlation analysis reported APA style:Pearson correlation conducted assess relationship participants' age scores cognitive ability test. Assumptions checks performed ensure violation assumptions normality, linearity, homoscedasticity. significant negative correlation age cognitive ability scores, r(98) = -.45, p < .001, older participants tending lower scores cognitive ability test. , null hypothesis can rejected.example hypothesis simple linear regression analysis:Null Hypothesis (H0): number study hours significant predictor test scores.Alternative Hypothesis (H1): number study hours significant predictor test scores.example simple linear regression analysis reported APA style:simple linear regression conducted predict test scores based number study hours. assumptions linearity, independence, normality checked met.regression equation found : Test Score = 50.2 + 6.7 * Study Hours.results indicated significant relationship number study hours test scores, F(1, 98) = 34.5, p < .001. , null hypothesis can rejected R² value .26, indicating approximately 26% variance test scores can explained number study hours.additional hour study, increase 6.7 points test score. intercept value 50.2 indicates student study (0 hours) expected score 50.2 points test.","code":""},{"path":"multiple-regression.html","id":"multiple-regression","chapter":"5 Multiple regression","heading":"5 Multiple regression","text":"Multiple regression method helps us predict outcome variable based several independent variables. technique tells us variables important predicting outcome, predictor variables interact. building prediction model, multiple regression allows us understand variables connected helps us make powerful data-informed decisions.","code":""},{"path":"multiple-regression.html","id":"shared-variance-with-mulitple-variables","chapter":"5 Multiple regression","heading":"5.1 Shared variance with mulitple variables","text":"previous chapter simple linear regression, suggested one predictor variable (exercise) shared variance another variable (well-). Visually, can represented using Venn diagram two circles: one exercise one well-.overlap two circles represents shared variance, extent variations exercise can explain variations well-. shared variance can represented numerically square correlation coefficient two variables. hypothetical example exercise correlated well-correlation coefficent r=0.46 (.e. moderate-positive correlation) , , can said exercise explains 21% variance well-(\\(R^2\\)=0.21)multiple regression analysis, use two independent variables predict value dependent variable (also referred criterion variable). , independent variable may share variance dependent variable, also share variance among independent variables. Understanding shared variance crucial interpreting results multiple regression analysis.instance, say using three independent variables predict well-: exercise, age, income. variables contribute variance well-.add variables one--one, overlap independent variable circle well-circle represents unique variance variable contributes well-.Adding age data participant, might see significant correlations three different relationships. Perhaps positive correlation exercise well-, negative correlations age well-(older people may deal health issues reduce well-), another negative correlation age exercise (older people may exercise less).age exercise now explain variability well-, since also related , variance explain overlaps.Finally, add income can see variable shares variance age well-. Adding variance explained model also overlapping variance explained ageThe outcome variable add allowed us better explain concept well-. , know person's amount exercise, age, income predict well-greater degree just know amount exercise.","code":""},{"path":"multiple-regression.html","id":"the-regression-equasion","chapter":"5 Multiple regression","heading":"5.2 The Regression Equasion","text":"probably realized, using Venn diagrams illustrate relationships among multiple variables can get quite confusing, especially numerous variables degree correlation . regression equation comes handy.regression equation mathematical representation relationships among variables multiple regression analysis. shows outcome variable (also called dependent variable) predicted independent variables. simplest form, regression equation can written :\\[ y = \\beta_0 + \\beta_1x_1 + \\beta_2x_2 + \\ldots + \\beta_kx_k + \\varepsilon \\], \\(y\\) dependent variable, \\(x_1\\), \\(x_2\\),...,\\(x_k\\) independent variables, \\(\\beta_0\\) intercept, \\(\\beta_1\\), \\(\\beta_2\\),...,\\(\\beta_k\\) coefficients independent variables, \\(\\varepsilon\\) error term, representing unexplained variability dependent variable (.e. left white space Venn diagram figure ).coefficients (\\(\\beta\\) values) represent average change dependent variable one-unit change respective independent variable, holding variables constant.intercept \\(\\beta_0\\) represents value dependent variable independent variables zero (just like equation line last week)Running regression analysis allowed us substituent number sof coefficients degree left \\(x\\)'s can use sub data.Explain shared variance workes multiple variablesExplain regression equasion changesexplain interprate results regression modelFull explaner resudials role assumption checksshow example multiple regression health environmental psych paper","code":""}]
